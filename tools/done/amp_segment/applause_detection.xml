<tool id="applause_detection" name="Applause Detection" version="1.0.0">
  <description>Detect segments of applause vs non-applause using Tensorflow</description>
  <requirements>
	<requirement type="package" version="3.8">python</requirement>
    <requirement type="package" version="0.7.2">librosa</requirement>
	<requirement type="package" version="1.17.4">numpy</requirement>
    <requirement type="package" version="0.9.2">numpydoc</requirement>
	<requirement type="package" version="0.48">numba</requirement>
    <requirement type="package" version="1.4.1">scipy</requirement>
    <requirement type="package" version="0.22.1">scikit-learn</requirement>
    <requirement type="package" version="0.2.0">ffmpeg-python</requirement>
    <requirement type="package" version="2.0.1">tensorflow</requirement>
  </requirements>
  <command detect_errors="exit_code">
  	'$__tool_directory__/applause_detection.py' '$__root_dir__' '$input_audio' '$min_segment_duration' '$amp_applause_segments'
  </command>
  <inputs>
    <!-- should be wave data type -->
    <param name="input_audio" type="data" format="wav" label="Input Audio" help="Input audio file in wav format"/>
	<param name="min_segment_duration" type="integer" label="Minimum Segment Duration" value="1000" min="0" help="Minimum segment duration in miliseconds"/>
  </inputs>
  <outputs>
    <data name="amp_applause_segments" format="segment" label="AMP Applause Detection Segments"/>
  </outputs>
  <tests>
  </tests>
  <help>
.. class:: infomark

Detect segments of applause vs non-applause using Tensorflow. 
Segments of applause shorter than the minimum threshold are merged into the previous segment.

  </help>
</tool>
