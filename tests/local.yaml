# This is the default test suite -- local tools

### tools/applause_detection
- name: Applause Detection
  tool: applause_detection/applause_detection.xml
  inputs:
    input_audio: audio.mp3
  params:
    min_segment_duration: 3000
  outputs:
    amp_applause_segments:
      - [haskey, [json], 'segments']
      - [eq, [json, segments.0.label], non-applause]

### tools/gentle
- name: Gentle Forced Alignment
  tool: gentle/gentle_forced_alignment.xml
  inputs:
    speech_audio: audio.mp3
    amp_transcript_unaligned: amp_transcript_aws.json
  outputs:
    gentle_transcript:
      - [haskey, [json], words]
      - [contains, [json, transcript], "Many of Virgil's festivities"]
    amp_transcript_aligned:
      - [haskey, [json], results]    
      - [contains, [json, results.transcript], "Many of Virgil's festivities"]

### tools/ina_speech_segmenter
- name: INA Speech Segmenter
  tool: ina_speech_segmenter/ina_speech_segmenter.xml
  inputs:
    input_audio: audio.mp3
  outputs:
    amp_segments:
      - [haskey, [json], segments]
      - [eq, [json, segments.0.label], silence]
      

### tools/kaldi
# UGH, like the AWS transcribe, this is actually testing two scripts
- name: Kaldi
  tool: kaldi/kaldi.xml
  inputs:
    input_audio: audio.mp3
  outputs:
    kaldi_transcript_text:
      - [eq, [mime], text/plain]
      - [contains, [data], celebration of specialness]
    kaldi_transcript_json:
      - [haskey, [json], words]
      - [contains, [data], specialness]
    amp_transcript:
      - [haskey, [json], results]
      - [contains, [json, results.transcript], celebration of specialness]
      - [eq, [json, results.words.0.type], pronunciation]


### tools/mgms
- name: Adjust Diarization Timestamps
  tool: mgms/adjust_diarization_timestamps.xml
  tool: mgms/adjust_diarization_timestamps.xml
  inputs:
    amp_diarization_unadjusted: amp_diarization.json
    kept_segments: amp_kept_segments.json
  outputs:
    amp_diarization_adjusted:
      - [eq, 26.065, [json, segments.0.end]]
      - [eq, 0, [json, numSpeakers]]
      - [eq, 44.3, [json, media.duration]]
      - [eq, spk_0, [json, segments.0.speakerLabel]]

- name: Adjust Transcript Timestamps
  tool: mgms/adjust_transcript_timestamps.xml
  inputs:
    amp_transcript_unadjusted: amp_transcript_aws.json
    kept_segments: amp_kept_segments.json
  outputs:
    amp_transcript_adjusted:
      - [haskey, [json], results]
      - [contains, [json, results.transcript], "Many of Virgil's festivities"]
      - [eq, [json, results.words.0.type], pronunciation]
      

- name: Applause Detection to Avalon XML
  tool: mgms/applause_detection_to_avalon_xml.xml
  skip: The code was broken prior to the refactoring.
  inputs:
    amp_applause_segments: applause_detection_segments.json
  params: 
    context_json: '{"itemName": "the item name", "primaryfileName": "The primary file name"}'
  outputs:
    avalon_applause_sme:
      # Need to write tests once this is fixed.
      - ['true']
    

- name: Adjust Transcript Timestamps
  tool: mgms/adjust_transcript_timestamps.xml
  inputs:
    amp_transcript_unadjusted: amp_transcript_aws.json
    kept_segments: amp_kept_segments.json
  outputs:
    amp_transcript_adjusted:
      - [haskey, [json], results]
      - [contains, [json, results.transcript], "Many of Virgil's festivities"]
      - [eq, [json, results.words.0.type], pronunciation]


- name: Contact Sheet - face
  tool: mgms/contact_sheet_face.xml
  inputs:
    input_video: video.m4v
    amp_faces: amp_faces.json
  params:
    type: faces
    margin: 10
    padding: 3
    columns: 4
    width: 300
  outputs:
    contact_sheet:
      - [eq, [media, container.mime_type], image/png]
      - [eq, [media, streams.image.0.codec], png]


- name: Contact Sheet - frame
  tool: mgms/contact_sheet_frame.xml
  inputs:
    input_video: video.m4v    
  params:    
    margin: 10
    padding: 3
    columns: 4
    width: 300
    frame_interval: 0
    frame_quantity: 12
  outputs:
    contact_sheet:
      - [eq, [media, container.mime_type], image/png]
      - [eq, [media, streams.image.0.codec], png]


- name: Contact Sheet - shot
  tool: mgms/contact_sheet_shot.xml
  inputs:
    input_video: video.m4v
    amp_shots: amp_shots.json
  params:
    type: shot
    margin: 10
    padding: 3
    columns: 4
    width: 300
  outputs:
    contact_sheet:
      - [eq, [media, container.mime_type], image/png]
      - [eq, [media, streams.image.0.codec], png]
      

- name: Contact Sheet - vocr
  tool: mgms/contact_sheet_vocr.xml
  inputs:
    input_video: video.m4v
    amp_vocr: vocr.json
  params:
    type: shot
    margin: 10
    padding: 3
    columns: 4
    width: 300
  outputs:
    contact_sheet:
      - [eq, [media, container.mime_type], image/png]
      - [eq, [media, streams.image.0.codec], png]


- name: Dlib Face Recognition
  tool: mgms/dlib_face_recognition.xml
  inputs:
    input_video: video.m4v
    training_photos: faces.zip
  params:
    reuse_trained: "no"
    tolerance: 0.6
  outputs:
    amp_faces:
      - [haskey, [json], frames]


- name: Extract Audio
  tool: mgms/extract_audio.xml
  inputs:
    input_av: video.m4v
  outputs:
    audio_extracted:
      - [eq, [media, container.format], wav]
      - [eq, [media, streams.audio.0.channels], 1]
      - [eq, [media, streams.audio.0.codec], pcm_s16le]
      - [eq, [media, streams.audio.0.sample_rate], 44100]
  params:    
    rate: 44100
    channels: 1
    sample_format: pcm_s16le


- name: INA Speech Segmenter
  tool: ina_speech_segmenter/ina_speech_segmenter.xml
  inputs:
    input_audio: audio.mp3
  outputs:
    amp_segments:
      - {test: magic, mime: [text/plain, application/json], comp: in}
      - {test: strings, strings: [segments, silence, gender, start, end]}


- name: Keep Speech
  tool: mgms/keep_speech.xml
  inputs:
    original_audio: audio.wav
    amp_segments: amp_segments.json
  outputs:
    speech_audio:
      - [eq, [media, container.format], wav]
    kept_segments:
      - [any, [mime], text/plain, application/json]      


- name: NER to CSV
  tool: mgms/ner_to_csv.xml
  inputs:
    amp_entities: amp_entities.ner
  outputs:
    amp_csv_entities:
      - [eq, [csv, 0, 0], Type]
      - [eq, [csv, 0, 1], Text]
      - [eq, [csv, 0, 2], Begin Offset]
      - [eq, [csv, 0, 3], End Offset]
      - [eq, [csv, 0, 4], Start Time]
      - [eq, [csv, 0, 5], Score Type]
      - [eq, [csv, 0, 6], Score Value]


- name: PyScene Detect
  tool: mgms/pyscenedetect.xml
  inputs:
    input_video: video.m4v
  params:
    threshold: 30
  outputs:
    amp_shots:
      - [haskey, [json], shots]
      - [eq, [json, shots.0.type], shot]
      - [eq, [json, shots.0.start], 0.0]      
    frame_stats:
      - [eq, [csv, 0, 0], Frame Number]
      - [eq, [csv, 0, 1], Timecode]
      - [eq, [csv, 0, 2], content_val]
      - [eq, [csv, 0, 3], delta_hue]
      - [eq, [csv, 0, 4], delta_lum]
      - [eq, [csv, 0, 5], delta_sat]


- name: Remove Silence Music Speech
  tool: mgms/remove_silence_speech.xml
  inputs:
    original_audio: audio.wav
    amp_segments: amp_segments.json
  outputs:
    music_audio:
      - [eq, [media, container.format], wav]
    kept_segments:
      - [any, [mime], text/plain, application/json]
      

- name: Remove Trailing Silence
  tool: mgms/remove_trailing_silence.xml
  inputs:
    input_av: audio.mp3
  outputs:
    audio_trimmed:
      - [eq, [media, container.format], wav]
      - [lt, [media, streams.audio.0.duration], 48]
    

- name: Spacy
  tool: mgms/spacy.xml
  inputs:
    amp_transcript: amp_transcript_aws.json
  params:
    ignore_types: QUANTITY
  outputs:
    spacy_entities:
      - [haskey, [json], text]
      - [haskey, [json], ents]
      - [contains, [json, text], "Many of Virgil's festivities"]
      - [eq, [json, ents.0.label], PERSON]
    amp_entities:
      - [haskey, [json], entities]
      - [eq, [json, entities.0.type], PERSON]


# Supplement doesn't really do anything, so skipping it.
#./mgms/supplement.xml


- name: Tesseract
  tool: mgms/tesseract.xml
  inputs:
    input_video: video.m4v
  params:
    vocr_interval: 1.0
    dedupe: "yes"
    dup_gap: 5
  outputs:
    amp_vocr:
      - [haskey, [json], frames]
      - [contains, [data], TRUE STORIES]
    amp_vocr_dedupe:
      - [haskey, [json], frames]
      - [contains, [data], TRUE STORIES]


- name: Transcript to WebVTT
  tool: mgms/transcript_to_webvtt.xml
  inputs:
    amp_diarization: amp_diarization.json
    amp_transcript: amp_transcript_aws.json
  outputs:
    web_vtt:
      - [contains, [data], WEBVTT]
      - [contains, [data], "Many of Virgil's festivities"]
      

- name: Vocabulary Tagging
  tool: mgms/vocabulary_tagging.xml
  inputs:
    amp_transcript: amp_transcript_aws.json
    tag_vocabulary: amp_words.txt
  outputs:
    tagged_words:
      - [eq, [csv, 0, 0], Word]
      - [eq, [csv, 0, 1], Start]


- name: VOCR to CSV
  tool: mgms/vocr_to_csv.xml
  inputs:
    amp_vocr: vocr.json
  outputs:
    amp_vocr_csv:
      - [eq, [csv, 0, 0], Start Time]
      - [eq, [csv, 0, 1], Text]
      - [eq, [csv, 0, 2], Language]
      - [eq, [csv, 0, 3], X Min]
      - [eq, [csv, 0, 4], Y Min]
      - [eq, [csv, 0, 5], X Max]
      - [eq, [csv, 0, 6], Y Max]
      - [eq, [csv, 0, 7], Score Type]
      - [eq, [csv, 0, 8], Score Value]
      
